{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "22091410",
      "metadata": {
        "id": "22091410"
      },
      "source": [
        "# Importing the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad74086",
      "metadata": {
        "id": "aad74086"
      },
      "outputs": [],
      "source": [
        "import collections.abc\n",
        "import collections\n",
        "import cv2\n",
        "import json\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import pycocotools\n",
        "import pylab\n",
        "import re\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import time as time\n",
        "import wget\n",
        "import zipfile\n",
        "\n",
        "from cv2 import dnn_superres\n",
        "from dict2xml import dict2xml\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from time import time\n",
        "\n",
        "from Cluster import *\n",
        "from Optimizer import *\n",
        "from OSCOD import *\n",
        "from Utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33de1471",
      "metadata": {
        "id": "33de1471"
      },
      "outputs": [],
      "source": [
        "#PLEASE DEFINE WHERE DO YOU WANT TO CREATE THE FOLDER TO SAVE THE SR MODEL\n",
        "OUTPUT_DIR = ''\n",
        "create_dir(OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1899bdd",
      "metadata": {
        "id": "e1899bdd"
      },
      "source": [
        "# Download Super-Resolution Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88c5084c",
      "metadata": {
        "id": "88c5084c",
        "outputId": "dbda7305-a141-47a0-d0e2-8f5460c5d832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r",
            "  0% [                                                          ]     0 / 38973\r",
            " 21% [............                                              ]  8192 / 38973\r",
            " 42% [........................                                  ] 16384 / 38973\r",
            " 63% [....................................                      ] 24576 / 38973\r",
            " 84% [................................................          ] 32768 / 38973\r",
            "100% [..........................................................] 38973 / 38973"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = 'FSRCNN_x2'\n",
        "MODEL_SR_DIR = OUTPUT_DIR+'MODEL_SR'\n",
        "create_dir(MODEL_SR_DIR)\n",
        "PATH_TO_MODEL_DIR = download_model_SR(MODEL_NAME, MODEL_SR_DIR+'/FSRCNN_x2.pb')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95da7587",
      "metadata": {
        "id": "95da7587"
      },
      "source": [
        "# Download Object Detection Model - EfficientDet D4\n",
        "\n",
        "The presented proposal can be executed with any model provided in Tensorflow Model Zoo. \n",
        "\n",
        "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
        "\n",
        "In this example, we are going to use EfficientDet D4 since it is one of the best performing models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "922ff8e9",
      "metadata": {
        "id": "922ff8e9"
      },
      "outputs": [],
      "source": [
        "MODEL_DATE = '20200711'\n",
        "MODEL_NAME = 'efficientdet_d4_coco17_tpu-32'\n",
        "PATH_TO_MODEL_DIR = download_model(MODEL_NAME, MODEL_DATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "717c78fd",
      "metadata": {
        "id": "717c78fd"
      },
      "source": [
        "# Download the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1666cb",
      "metadata": {
        "id": "ca1666cb"
      },
      "outputs": [],
      "source": [
        "LABEL_FILENAME = 'mscoco_complete_label_map.pbtxt'\n",
        "PATH_TO_LABELS = download_labels(LABEL_FILENAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45505583",
      "metadata": {
        "id": "45505583"
      },
      "source": [
        "# Loading the Object Detection Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d19de938",
      "metadata": {
        "id": "d19de938",
        "outputId": "c40167b0-cbe3-4b20-ba50-1d1c66dd49e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model..."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Importing a function (__inference_EfficientDet-D4_layer_call_and_return_conditional_losses_194916) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_EfficientDet-D4_layer_call_and_return_conditional_losses_167775) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_131153) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_134709) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference___call___46929) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_EfficientDet-D4_layer_call_and_return_conditional_losses_187495) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:absl:Importing a function (__inference_EfficientDet-D4_layer_call_and_return_conditional_losses_175196) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done! Took 39.44588780403137 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80b4d37c",
      "metadata": {
        "id": "80b4d37c"
      },
      "source": [
        "# Loading Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb6d61c",
      "metadata": {
        "id": "fdb6d61c"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dac3ff0b",
      "metadata": {
        "id": "dac3ff0b"
      },
      "source": [
        "# Start Our Proposal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd09394",
      "metadata": {
        "id": "8dd09394"
      },
      "outputs": [],
      "source": [
        "matplotlib.use('Agg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a22273e",
      "metadata": {
        "id": "6a22273e"
      },
      "outputs": [],
      "source": [
        "dict_COCO_names = {\n",
        "    1:\"person\", 2:\"bicycle\", 3:\"car\", 4:\"motorcycle\", 5:\"airplane\", 6:\"bus\", 7:\"train\", 8:\"truck\", 9:\"boat\", 10:\"traffic light\", 11:\"fire hydrant\", 12:\"street sign\", 13:\"stop sign\", 14:\"parking meter\", 15:\"bench\", 16:\"bird\", 17:\"cat\", 18:\"dog\", 19:\"horse\", 20:\"sheep\", 21:\"cow\", 22:\"elephant\", 23:\"bear\", 24:\"zebra\", 25:\"giraffe\", 26:\"hat\", 27:\"backpack\", 28:\"umbrella\", 29:\"shoe\", 30:\"eye glasses\", 31:\"handbag\", 32:\"tie\", 33:\"suitcase\", 34:\"frisbee\", 35:\"skis\", 36:\"snowboard\", 37:\"sports ball\", 38:\"kite\", 39:\"baseball bat\", 40:\"baseball glove\", 41:\"skateboard\", 42:\"surfboard\", 43:\"tennis racket\", 44:\"bottle\", 45:\"plate\", 46:\"wine glass\", 47:\"cup\", 48:\"fork\", 49:\"knife\", 50:\"spoon\", 51:\"bowl\", 52:\"banana\", 53:\"apple\", 54:\"sandwich\", 55:\"orange\", 56:\"broccoli\", 57:\"carrot\", 58:\"hot dog\", 59:\"pizza\", 60:\"donut\", 61:\"cake\", 62:\"chair\", 63:\"couch\", 64:\"potted plant\", 65:\"bed\", 66:\"mirror\", 67:\"dining table\", 68:\"window\", 69:\"desk\", 70:\"toilet\", 71:\"door\", 72:\"tv\", 73:\"laptop\", 74:\"mouse\", 75:\"remote\", 76:\"keyboard\", 77:\"cell phone\", 78:\"microwave\", 79:\"oven\", 80:\"toaster\", 81:\"sink\", 82:\"refrigerator\", 83:\"blender\", 84:\"book\", 85:\"clock\", 86:\"vase\", 87:\"scissors\", 88:\"teddy bear\", 89:\"hair drier\", 90:\"toothbrush\", 91:\"hair brush\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7186a328",
      "metadata": {
        "id": "7186a328"
      },
      "outputs": [],
      "source": [
        "#Arguments: make_inference_SRSR(model_loaded,category_index,path_image_infer,name_image,path_save_image_with_detections,clases_to_detect,% size of sub-imagen,% size of windows Size R,min_score_detect_element,path_model_sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Arguments: \n"
      ],
      "metadata": {
        "id": "UV7WzM2SI-Ct"
      },
      "id": "UV7WzM2SI-Ct"
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "make_inference_SRSR(\n",
        "  model_loaded, \n",
        "  category_index,\n",
        "  path_image_infer,\n",
        "  name_image,\n",
        "  path_save_image_with_detections,\n",
        "  clases_to_detect,\n",
        "  % size of sub-imagen,\n",
        "  % size of windows Size R,\n",
        "  min_score_detect_element,\n",
        "  path_model_sr\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "id": "C5uNEMAZJRes"
      },
      "id": "C5uNEMAZJRes",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb849ace",
      "metadata": {
        "id": "fb849ace"
      },
      "outputs": [],
      "source": [
        "make_inference_SRSR(detect_fn,category_index,'/opt/share/Github/TEST/0.jpg','salida.jpg','/opt/share/Github/TEST/PRUEBA',[3],0.5,0,0.35,'/opt/share/Github/TEST/MODEL_SR/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other proposals presented in the paper."
      ],
      "metadata": {
        "id": "viqaFovJK5NY"
      },
      "id": "viqaFovJK5NY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2451a983",
      "metadata": {
        "id": "2451a983"
      },
      "outputs": [],
      "source": [
        "make_inference_SRSR(detect_fn,category_index,'/opt/share/ES/0000213_03920_d_0000243.jpg','salidav2ours.jpg','/opt/share/Github/TEST/PRUEBA',[3],0.5,0.5,0.5,'/opt/share/Github/TEST/MODEL_SR/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea1b84b8",
      "metadata": {
        "id": "ea1b84b8"
      },
      "outputs": [],
      "source": [
        "make_inference_SRSRRAW(detect_fn,category_index,'/opt/share/ES/0000213_03920_d_0000243.jpg','salidav2raw.jpg','/opt/share/Github/TEST/PRUEBA',[3],0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation with different models and Windows Size R:"
      ],
      "metadata": {
        "id": "4U5iDmcgJlvL"
      },
      "id": "4U5iDmcgJlvL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6c5ef05",
      "metadata": {
        "id": "e6c5ef05"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import json\n",
        "import time\n",
        "\n",
        "#PLEASE INSERT THE PATH TO GENERATE THE OUTPUTS\n",
        "PATH_EVAL = ''\n",
        "    \n",
        "#PLEASE INSERT THE PATH OF EVERY SEQUENCE\n",
        "SEQ_DATA_VAL = ['/opt/share/DATA-CLICK/NGSIM-Dataset-Annotations-main/Sequence1/images/test/','/opt/share/DATA-CLICK/NGSIM-Dataset-Annotations-main/Sequence2/images/test/','/opt/share/DATA-CLICK/NGSIM-Dataset-Annotations-main/Sequence3/images/test/','/opt/share/DATA-CLICK/NGSIM-Dataset-Annotations-main/Sequence4/images/test/']\n",
        "SEQ_DATA_NAME = ['SEQ1','SEQ2','SEQ3','SEQ4']\n",
        "SEQ_DATA_GT = ['/opt/share/DATA-CLICK/NGSIM-Dataset-Annotations-main/Sequence1/annotations/GT.json','/opt/share/DATA-CLICK/NGSIM-Dataset-Annotations-main/Sequence2/annotations/GT.json','/opt/share/DATA-CLICK/NGSIM-Dataset-Annotations-main/Sequence3/annotations/GT.json','/opt/share/DATA-CLICK/NGSIM-Dataset-Annotations-main/Sequence4/annotations/GT.json',]\n",
        "\n",
        "#SELECTION OF DIFFERENT PRE-TRAINED MODELS\n",
        "MODELS_P1 = ['20200711','20200711','20200711','20200711','20200711','20200711']\n",
        "MODELS_P2 = ['centernet_hg104_1024x1024_kpts_coco17_tpu-32','centernet_resnet101_v1_fpn_512x512_coco17_tpu-8','faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8','efficientdet_d3_coco17_tpu-32','efficientdet_d4_coco17_tpu-32','efficientdet_d5_coco17_tpu-32']\n",
        "MODELS_NAMES = ['CENTERNET-HG104KPT1024','CENTERNET-RESNET101-V1','FASTER-INCEPTION-RESNET-V2-1024','ED3','ED4','ED5']\n",
        "\n",
        "#PLEASE INSERT THE CLASSES (COCO) THAT YOU WANT TO DETECT\n",
        "CLASES = [3]\n",
        "        \n",
        "#PLEASE INSERT THE MINIMUN SCORE TO DETECT ONE OBJECT\n",
        "SCORE = 0.35\n",
        "\n",
        "#PLEASE INSERT % OF THE WINDOWS SIZE R TO BE EVALLUATED\n",
        "WSizeR = [0, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1]\n",
        "\n",
        "for modelo_selected in range(len(MODELS_P1)):\n",
        "    MODEL_DATE = MODELS_P1[modelo_selected]\n",
        "    MODEL_NAME = MODELS_P2[modelo_selected]\n",
        "\n",
        "    PATH_TO_MODEL_DIR = download_model(MODEL_NAME, MODEL_DATE)\n",
        "    LABEL_FILENAME = 'mscoco_complete_label_map.pbtxt'\n",
        "    PATH_TO_LABELS = download_labels(LABEL_FILENAME)\n",
        "    PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "    print('Loading model...', end='')\n",
        "    start_time = time.time()\n",
        "    detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "    category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "    for seq_selected in range(len(SEQ_DATA_VAL)):\n",
        "        \n",
        "        jsonString = SEQ_DATA_GT[seq_selected]\n",
        "        dict_ids = {}\n",
        "\n",
        "        with open(jsonString) as json_file:\n",
        "            data = json.load(json_file)\n",
        "            for p3 in data['images']:\n",
        "                data_s_image = p3['file_name'].replace('images/','')\n",
        "                data_s_id = p3['id']\n",
        "                dict_ids[data_s_image] = data_s_id\n",
        "                \n",
        "        imagenes_dir_train = SEQ_DATA_VAL[seq_selected]\n",
        "\n",
        "        for parte in range(len(WSizeR)):\n",
        "\n",
        "            MODEL = MODELS_NAMES[modelo_selected]+'/'+SEQ_DATA_NAME[seq_selected]\n",
        "            MODEL = MODEL+'/'+str(WSizeR[parte])\n",
        "            test_dataset = os.listdir(imagenes_dir_train)\n",
        "\n",
        "            create_dir(PATH_EVAL+MODEL)\n",
        "            create_dir(PATH_EVAL+MODEL+'/FACTOR-OPT/SALIDA/')\n",
        "            create_dir(PATH_EVAL+MODEL+'/AUX/')\n",
        "            create_dir(PATH_EVAL+MODEL+'/JSON/')\n",
        "            PATH_AUX = PATH_EVAL+MODEL+'/AUX/'\n",
        "\n",
        "            OPTIMIZATION = WSizeR[parte]\n",
        "            WINDOW_SIZE  = 0.50\n",
        "\n",
        "            imagenes_dir3 = imagenes_dir_train\n",
        "            frames_test = os.listdir(imagenes_dir_train)\n",
        "            imagenes_dir2 = []\n",
        "            counter = 0\n",
        "\n",
        "            result = []\n",
        "            result2 = []\n",
        "            resultaux = []\n",
        "            out = []\n",
        "            out2 = []\n",
        "            outaux = []\n",
        "\n",
        "            for frame in frames_test:\n",
        "              id = frame.replace('.jpg','')\n",
        "              image_path_save = imagenes_dir_train+\"/\"+str(frame)\n",
        "              output = make_inference_SRSR(detect_fn,category_index,image_path_save,frame,PATH_EVAL+'/'+MODEL+'/FACTOR-OPT/',CLASES,WINDOW_SIZE,OPTIMIZATION,SCORE,MODEL_SR_DIR+'/')   \n",
        "              counter = counter+1\n",
        "\n",
        "              result = []\n",
        "              result2 = []\n",
        "              resultaux = []\n",
        "              out2= []\n",
        "              converted_num = dict_ids[frame]\n",
        "              width = output[3]\n",
        "              height = output[4]\n",
        "              boxes2 = []\n",
        "\n",
        "              for box in output[0]:\n",
        "                ymin = int(box[0]*height)\n",
        "                xmin = int(box[1]*width)\n",
        "                ymax = int(box[2]*height)\n",
        "                xmax = int(box[3]*width) \n",
        "                box_new = []\n",
        "                box_new.append(xmin)\n",
        "                box_new.append(ymin)\n",
        "                box_new.append(xmax-xmin)\n",
        "                box_new.append(ymax-ymin)\n",
        "                boxes2.append(box_new)\n",
        "\n",
        "              result.extend(\n",
        "                    [\n",
        "                        {\n",
        "                            \"image_id\": converted_num,\n",
        "                            \"category_id\": int(output[2][k]),\n",
        "                            \"bbox\": box,\n",
        "                            \"score\": output[1][k].astype(float),\n",
        "                        }\n",
        "                        for k, box in enumerate(boxes2)\n",
        "                    ]\n",
        "              )\n",
        "\n",
        "              result2.extend(\n",
        "                    [\n",
        "                        {\n",
        "                            \"image_id\": converted_num,\n",
        "                            \"category_id\": int(output[2][k]),\n",
        "                            \"bbox\": box,\n",
        "                            \"score\": output[1][k].astype(float),\n",
        "                        }\n",
        "                        for k, box in enumerate(boxes2)\n",
        "                    ]\n",
        "              )\n",
        "\n",
        "              cluster_converted = []\n",
        "              raw_subimages = output[6]\n",
        "              ours_subimages = output[7]\n",
        "\n",
        "              for indexcluster in range(len(output[5])):\n",
        "                    tripla = output[5][indexcluster]\n",
        "                    lista_boxes_lista = tripla[0].tolist()\n",
        "                    lista_clases_lista = tripla[1].tolist()\n",
        "                    lista_scores_lista = tripla[2].tolist()\n",
        "                    cluster_aux = []\n",
        "                    cluster_aux.append(lista_boxes_lista)\n",
        "                    cluster_aux.append(lista_clases_lista)\n",
        "                    cluster_aux.append(lista_scores_lista)\n",
        "                    cluster_converted.append(cluster_aux)\n",
        "\n",
        "              resultaux.extend(\n",
        "                [\n",
        "                    {\n",
        "                        \"image_id\": converted_num,\n",
        "                        \"triplas\": cluster_converted,\n",
        "                        \"number_subimages\": int(ours_subimages),\n",
        "                        \"number_subimages_without_proposal\":int(raw_subimages),\n",
        "                    }\n",
        "                ]\n",
        "              )\n",
        "\n",
        "\n",
        "              for save_file in result2:    \n",
        "                    out2.append(save_file)\n",
        "\n",
        "              json_file = PATH_EVAL+MODEL+'/JSON/'+str(converted_num)+'.json'\n",
        "              with open(json_file, 'w', encoding='utf-8') as save_files:\n",
        "                json.dump(out2, save_files, ensure_ascii=False)\n",
        "\n",
        "              for sample in result:    \n",
        "                    out.append(sample)\n",
        "\n",
        "              for sampleaux in resultaux:    \n",
        "                    outaux.append(sampleaux)\n",
        "\n",
        "            with open(PATH_EVAL+MODEL+'/'+'test_data_modificado.json', 'w', encoding='utf-8') as file:\n",
        "              json.dump(out, file, ensure_ascii=False)\n",
        "\n",
        "            with open(PATH_EVAL+MODEL+'/'+'test_data_modificado2.json', 'w', encoding='utf-8') as fileaux:\n",
        "              json.dump(outaux, fileaux, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00daaa83",
      "metadata": {
        "id": "00daaa83"
      },
      "outputs": [],
      "source": [
        "#Please insert a path to automatize the saving of data and executing the following cell\n",
        "path_auto = ''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "__author__ = 'tsungyi'\n",
        "\n",
        "import numpy as np\n",
        "import datetime\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import mask as maskUtils\n",
        "import copy\n",
        "import json\n",
        "\n",
        "class COCOeval:\n",
        "    # Interface for evaluating detection on the Microsoft COCO dataset.\n",
        "    #\n",
        "    # The usage for CocoEval is as follows:\n",
        "    #  cocoGt=..., cocoDt=...       # load dataset and results\n",
        "    #  E = CocoEval(cocoGt,cocoDt); # initialize CocoEval object\n",
        "    #  E.params.recThrs = ...;      # set parameters as desired\n",
        "    #  E.evaluate();                # run per image evaluation\n",
        "    #  E.accumulate();              # accumulate per image results\n",
        "    #  E.summarize();               # display summary metrics of results\n",
        "    # For example usage see evalDemo.m and http://mscoco.org/.\n",
        "    #\n",
        "    # The evaluation parameters are as follows (defaults in brackets):\n",
        "    #  imgIds     - [all] N img ids to use for evaluation\n",
        "    #  catIds     - [all] K cat ids to use for evaluation\n",
        "    #  iouThrs    - [.5:.05:.95] T=10 IoU thresholds for evaluation\n",
        "    #  recThrs    - [0:.01:1] R=101 recall thresholds for evaluation\n",
        "    #  areaRng    - [...] A=4 object area ranges for evaluation\n",
        "    #  maxDets    - [1 10 100] M=3 thresholds on max detections per image\n",
        "    #  iouType    - ['segm'] set iouType to 'segm', 'bbox' or 'keypoints'\n",
        "    #  iouType replaced the now DEPRECATED useSegm parameter.\n",
        "    #  useCats    - [1] if true use category labels for evaluation\n",
        "    # Note: if useCats=0 category labels are ignored as in proposal scoring.\n",
        "    # Note: multiple areaRngs [Ax2] and maxDets [Mx1] can be specified.\n",
        "    #\n",
        "    # evaluate(): evaluates detections on every image and every category and\n",
        "    # concats the results into the \"evalImgs\" with fields:\n",
        "    #  dtIds      - [1xD] id for each of the D detections (dt)\n",
        "    #  gtIds      - [1xG] id for each of the G ground truths (gt)\n",
        "    #  dtMatches  - [TxD] matching gt id at each IoU or 0\n",
        "    #  gtMatches  - [TxG] matching dt id at each IoU or 0\n",
        "    #  dtScores   - [1xD] confidence of each dt\n",
        "    #  gtIgnore   - [1xG] ignore flag for each gt\n",
        "    #  dtIgnore   - [TxD] ignore flag for each dt at each IoU\n",
        "    #\n",
        "    # accumulate(): accumulates the per-image, per-category evaluation\n",
        "    # results in \"evalImgs\" into the dictionary \"eval\" with fields:\n",
        "    #  params     - parameters used for evaluation\n",
        "    #  date       - date evaluation was performed\n",
        "    #  counts     - [T,R,K,A,M] parameter dimensions (see above)\n",
        "    #  precision  - [TxRxKxAxM] precision for every evaluation setting\n",
        "    #  recall     - [TxKxAxM] max recall for every evaluation setting\n",
        "    # Note: precision and recall==-1 for settings with no gt objects.\n",
        "    #\n",
        "    # See also coco, mask, pycocoDemo, pycocoEvalDemo\n",
        "    #\n",
        "    # Microsoft COCO Toolbox.      version 2.0\n",
        "    # Data, paper, and tutorials available at:  http://mscoco.org/\n",
        "    # Code written by Piotr Dollar and Tsung-Yi Lin, 2015.\n",
        "    # Licensed under the Simplified BSD License [see coco/license.txt]\n",
        "    def __init__(self, cocoGt=None, cocoDt=None, iouType='segm'):\n",
        "        '''\n",
        "        Initialize CocoEval using coco APIs for gt and dt\n",
        "        :param cocoGt: coco object with ground truth annotations\n",
        "        :param cocoDt: coco object with detection results\n",
        "        :return: None\n",
        "        '''\n",
        "        if not iouType:\n",
        "            print('iouType not specified. use default iouType segm')\n",
        "        self.cocoGt   = cocoGt              # ground truth COCO API\n",
        "        self.cocoDt   = cocoDt              # detections COCO API\n",
        "        self.evalImgs = defaultdict(list)   # per-image per-category evaluation results [KxAxI] elements\n",
        "        self.eval     = {}                  # accumulated evaluation results\n",
        "        self._gts = defaultdict(list)       # gt for evaluation\n",
        "        self._dts = defaultdict(list)       # dt for evaluation\n",
        "        self.params = Params(iouType=iouType) # parameters\n",
        "        self._paramsEval = {}               # parameters for evaluation\n",
        "        self.stats = []                     # result summarization\n",
        "        self.ious = {}                      # ious between all gts and dts\n",
        "        if not cocoGt is None:\n",
        "            self.params.imgIds = sorted(cocoGt.getImgIds())\n",
        "            self.params.catIds = sorted(cocoGt.getCatIds())\n",
        "\n",
        "\n",
        "    def _prepare(self):\n",
        "        '''\n",
        "        Prepare ._gts and ._dts for evaluation based on params\n",
        "        :return: None\n",
        "        '''\n",
        "        def _toMask(anns, coco):\n",
        "            # modify ann['segmentation'] by reference\n",
        "            for ann in anns:\n",
        "                rle = coco.annToRLE(ann)\n",
        "                ann['segmentation'] = rle\n",
        "        p = self.params\n",
        "        if p.useCats:\n",
        "            gts=self.cocoGt.loadAnns(self.cocoGt.getAnnIds(imgIds=p.imgIds, catIds=p.catIds))\n",
        "            dts=self.cocoDt.loadAnns(self.cocoDt.getAnnIds(imgIds=p.imgIds, catIds=p.catIds))\n",
        "        else:\n",
        "            gts=self.cocoGt.loadAnns(self.cocoGt.getAnnIds(imgIds=p.imgIds))\n",
        "            dts=self.cocoDt.loadAnns(self.cocoDt.getAnnIds(imgIds=p.imgIds))\n",
        "\n",
        "        # convert ground truth to mask if iouType == 'segm'\n",
        "        if p.iouType == 'segm':\n",
        "            _toMask(gts, self.cocoGt)\n",
        "            _toMask(dts, self.cocoDt)\n",
        "        # set ignore flag\n",
        "        for gt in gts:\n",
        "            gt['ignore'] = gt['ignore'] if 'ignore' in gt else 0\n",
        "            gt['ignore'] = 'iscrowd' in gt and gt['iscrowd']\n",
        "            if p.iouType == 'keypoints':\n",
        "                gt['ignore'] = (gt['num_keypoints'] == 0) or gt['ignore']\n",
        "        self._gts = defaultdict(list)       # gt for evaluation\n",
        "        self._dts = defaultdict(list)       # dt for evaluation\n",
        "        for gt in gts:\n",
        "            self._gts[gt['image_id'], gt['category_id']].append(gt)\n",
        "        for dt in dts:\n",
        "            self._dts[dt['image_id'], dt['category_id']].append(dt)\n",
        "        self.evalImgs = defaultdict(list)   # per-image per-category evaluation results\n",
        "        self.eval     = {}                  # accumulated evaluation results\n",
        "\n",
        "    def evaluate(self):\n",
        "        '''\n",
        "        Run per image evaluation on given images and store results (a list of dict) in self.evalImgs\n",
        "        :return: None\n",
        "        '''\n",
        "        tic = time.time()\n",
        "        print('Running per image evaluation...')\n",
        "        p = self.params\n",
        "        # add backward compatibility if useSegm is specified in params\n",
        "        if not p.useSegm is None:\n",
        "            p.iouType = 'segm' if p.useSegm == 1 else 'bbox'\n",
        "            print('useSegm (deprecated) is not None. Running {} evaluation'.format(p.iouType))\n",
        "        print('Evaluate annotation type *{}*'.format(p.iouType))\n",
        "        p.imgIds = list(np.unique(p.imgIds))\n",
        "        if p.useCats:\n",
        "            p.catIds = list(np.unique(p.catIds))\n",
        "        p.maxDets = sorted(p.maxDets)\n",
        "        self.params=p\n",
        "\n",
        "        self._prepare()\n",
        "        # loop through images, area range, max detection number\n",
        "        catIds = p.catIds if p.useCats else [-1]\n",
        "\n",
        "        if p.iouType == 'segm' or p.iouType == 'bbox':\n",
        "            computeIoU = self.computeIoU\n",
        "        elif p.iouType == 'keypoints':\n",
        "            computeIoU = self.computeOks\n",
        "        self.ious = {(imgId, catId): computeIoU(imgId, catId) \\\n",
        "                        for imgId in p.imgIds\n",
        "                        for catId in catIds}\n",
        "\n",
        "        evaluateImg = self.evaluateImg\n",
        "        maxDet = p.maxDets[-1]\n",
        "        self.evalImgs = [evaluateImg(imgId, catId, areaRng, maxDet)\n",
        "                 for catId in catIds\n",
        "                 for areaRng in p.areaRng\n",
        "                 for imgId in p.imgIds\n",
        "             ]\n",
        "        self._paramsEval = copy.deepcopy(self.params)\n",
        "        toc = time.time()\n",
        "        print('DONE (t={:0.2f}s).'.format(toc-tic))\n",
        "\n",
        "    def computeIoU(self, imgId, catId):\n",
        "        p = self.params\n",
        "        if p.useCats:\n",
        "            gt = self._gts[imgId,catId]\n",
        "            dt = self._dts[imgId,catId]\n",
        "        else:\n",
        "            gt = [_ for cId in p.catIds for _ in self._gts[imgId,cId]]\n",
        "            dt = [_ for cId in p.catIds for _ in self._dts[imgId,cId]]\n",
        "        if len(gt) == 0 and len(dt) ==0:\n",
        "            return []\n",
        "        inds = np.argsort([-d['score'] for d in dt], kind='mergesort')\n",
        "        dt = [dt[i] for i in inds]\n",
        "        if len(dt) > p.maxDets[-1]:\n",
        "            dt=dt[0:p.maxDets[-1]]\n",
        "\n",
        "        if p.iouType == 'segm':\n",
        "            g = [g['segmentation'] for g in gt]\n",
        "            d = [d['segmentation'] for d in dt]\n",
        "        elif p.iouType == 'bbox':\n",
        "            g = [g['bbox'] for g in gt]\n",
        "            d = [d['bbox'] for d in dt]\n",
        "        else:\n",
        "            raise Exception('unknown iouType for iou computation')\n",
        "\n",
        "        # compute iou between each dt and gt region\n",
        "        iscrowd = [int(o['iscrowd']) for o in gt]\n",
        "        ious = maskUtils.iou(d,g,iscrowd)\n",
        "        return ious\n",
        "\n",
        "    def computeOks(self, imgId, catId):\n",
        "        p = self.params\n",
        "        # dimention here should be Nxm\n",
        "        gts = self._gts[imgId, catId]\n",
        "        dts = self._dts[imgId, catId]\n",
        "        inds = np.argsort([-d['score'] for d in dts], kind='mergesort')\n",
        "        dts = [dts[i] for i in inds]\n",
        "        if len(dts) > p.maxDets[-1]:\n",
        "            dts = dts[0:p.maxDets[-1]]\n",
        "        # if len(gts) == 0 and len(dts) == 0:\n",
        "        if len(gts) == 0 or len(dts) == 0:\n",
        "            return []\n",
        "        ious = np.zeros((len(dts), len(gts)))\n",
        "        sigmas = p.kpt_oks_sigmas\n",
        "        vars = (sigmas * 2)**2\n",
        "        k = len(sigmas)\n",
        "        # compute oks between each detection and ground truth object\n",
        "        for j, gt in enumerate(gts):\n",
        "            # create bounds for ignore regions(double the gt bbox)\n",
        "            g = np.array(gt['keypoints'])\n",
        "            xg = g[0::3]; yg = g[1::3]; vg = g[2::3]\n",
        "            k1 = np.count_nonzero(vg > 0)\n",
        "            bb = gt['bbox']\n",
        "            x0 = bb[0] - bb[2]; x1 = bb[0] + bb[2] * 2\n",
        "            y0 = bb[1] - bb[3]; y1 = bb[1] + bb[3] * 2\n",
        "            for i, dt in enumerate(dts):\n",
        "                d = np.array(dt['keypoints'])\n",
        "                xd = d[0::3]; yd = d[1::3]\n",
        "                if k1>0:\n",
        "                    # measure the per-keypoint distance if keypoints visible\n",
        "                    dx = xd - xg\n",
        "                    dy = yd - yg\n",
        "                else:\n",
        "                    # measure minimum distance to keypoints in (x0,y0) & (x1,y1)\n",
        "                    z = np.zeros((k))\n",
        "                    dx = np.max((z, x0-xd),axis=0)+np.max((z, xd-x1),axis=0)\n",
        "                    dy = np.max((z, y0-yd),axis=0)+np.max((z, yd-y1),axis=0)\n",
        "                e = (dx**2 + dy**2) / vars / (gt['area']+np.spacing(1)) / 2\n",
        "                if k1 > 0:\n",
        "                    e=e[vg > 0]\n",
        "                ious[i, j] = np.sum(np.exp(-e)) / e.shape[0]\n",
        "        return ious\n",
        "\n",
        "    def evaluateImg(self, imgId, catId, aRng, maxDet):\n",
        "        '''\n",
        "        perform evaluation for single category and image\n",
        "        :return: dict (single image results)\n",
        "        '''\n",
        "        p = self.params\n",
        "        if p.useCats:\n",
        "            gt = self._gts[imgId,catId]\n",
        "            dt = self._dts[imgId,catId]\n",
        "        else:\n",
        "            gt = [_ for cId in p.catIds for _ in self._gts[imgId,cId]]\n",
        "            dt = [_ for cId in p.catIds for _ in self._dts[imgId,cId]]\n",
        "        if len(gt) == 0 and len(dt) ==0:\n",
        "            return None\n",
        "\n",
        "        for g in gt:\n",
        "            if g['ignore'] or (g['area']<aRng[0] or g['area']>aRng[1]):\n",
        "                g['_ignore'] = 1\n",
        "            else:\n",
        "                g['_ignore'] = 0\n",
        "\n",
        "        # sort dt highest score first, sort gt ignore last\n",
        "        gtind = np.argsort([g['_ignore'] for g in gt], kind='mergesort')\n",
        "        gt = [gt[i] for i in gtind]\n",
        "        dtind = np.argsort([-d['score'] for d in dt], kind='mergesort')\n",
        "        dt = [dt[i] for i in dtind[0:maxDet]]\n",
        "        iscrowd = [int(o['iscrowd']) for o in gt]\n",
        "        # load computed ious\n",
        "        ious = self.ious[imgId, catId][:, gtind] if len(self.ious[imgId, catId]) > 0 else self.ious[imgId, catId]\n",
        "\n",
        "        T = len(p.iouThrs)\n",
        "        G = len(gt)\n",
        "        D = len(dt)\n",
        "        gtm  = np.zeros((T,G))\n",
        "        dtm  = np.zeros((T,D))\n",
        "        gtIg = np.array([g['_ignore'] for g in gt])\n",
        "        dtIg = np.zeros((T,D))\n",
        "        if not len(ious)==0:\n",
        "            for tind, t in enumerate(p.iouThrs):\n",
        "                for dind, d in enumerate(dt):\n",
        "                    # information about best match so far (m=-1 -> unmatched)\n",
        "                    iou = min([t,1-1e-10])\n",
        "                    m   = -1\n",
        "                    for gind, g in enumerate(gt):\n",
        "                        # if this gt already matched, and not a crowd, continue\n",
        "                        if gtm[tind,gind]>0 and not iscrowd[gind]:\n",
        "                            continue\n",
        "                        # if dt matched to reg gt, and on ignore gt, stop\n",
        "                        if m>-1 and gtIg[m]==0 and gtIg[gind]==1:\n",
        "                            break\n",
        "                        # continue to next gt unless better match made\n",
        "                        if ious[dind,gind] < iou:\n",
        "                            continue\n",
        "                        # if match successful and best so far, store appropriately\n",
        "                        iou=ious[dind,gind]\n",
        "                        m=gind\n",
        "                    # if match made store id of match for both dt and gt\n",
        "                    if m ==-1:\n",
        "                        continue\n",
        "                    dtIg[tind,dind] = gtIg[m]\n",
        "                    dtm[tind,dind]  = gt[m]['id']\n",
        "                    gtm[tind,m]     = d['id']\n",
        "        # set unmatched detections outside of area range to ignore\n",
        "        a = np.array([d['area']<aRng[0] or d['area']>aRng[1] for d in dt]).reshape((1, len(dt)))\n",
        "        dtIg = np.logical_or(dtIg, np.logical_and(dtm==0, np.repeat(a,T,0)))\n",
        "        # store results for given image and category\n",
        "        return {\n",
        "                'image_id':     imgId,\n",
        "                'category_id':  catId,\n",
        "                'aRng':         aRng,\n",
        "                'maxDet':       maxDet,\n",
        "                'dtIds':        [d['id'] for d in dt],\n",
        "                'gtIds':        [g['id'] for g in gt],\n",
        "                'dtMatches':    dtm,\n",
        "                'gtMatches':    gtm,\n",
        "                'dtScores':     [d['score'] for d in dt],\n",
        "                'gtIgnore':     gtIg,\n",
        "                'dtIgnore':     dtIg,\n",
        "            }\n",
        "\n",
        "    def accumulate(self, p = None):\n",
        "        '''\n",
        "        Accumulate per image evaluation results and store the result in self.eval\n",
        "        :param p: input params for evaluation\n",
        "        :return: None\n",
        "        '''\n",
        "        print('Accumulating evaluation results...')\n",
        "        tic = time.time()\n",
        "        if not self.evalImgs:\n",
        "            print('Please run evaluate() first')\n",
        "        # allows input customized parameters\n",
        "        if p is None:\n",
        "            p = self.params\n",
        "        p.catIds = p.catIds if p.useCats == 1 else [-1]\n",
        "        T           = len(p.iouThrs)\n",
        "        R           = len(p.recThrs)\n",
        "        K           = len(p.catIds) if p.useCats else 1\n",
        "        A           = len(p.areaRng)\n",
        "        M           = len(p.maxDets)\n",
        "        precision   = -np.ones((T,R,K,A,M)) # -1 for the precision of absent categories\n",
        "        recall      = -np.ones((T,K,A,M))\n",
        "        scores      = -np.ones((T,R,K,A,M))\n",
        "\n",
        "        # create dictionary for future indexing\n",
        "        _pe = self._paramsEval\n",
        "        catIds = _pe.catIds if _pe.useCats else [-1]\n",
        "        setK = set(catIds)\n",
        "        setA = set(map(tuple, _pe.areaRng))\n",
        "        setM = set(_pe.maxDets)\n",
        "        setI = set(_pe.imgIds)\n",
        "        # get inds to evaluate\n",
        "        k_list = [n for n, k in enumerate(p.catIds)  if k in setK]\n",
        "        m_list = [m for n, m in enumerate(p.maxDets) if m in setM]\n",
        "        a_list = [n for n, a in enumerate(map(lambda x: tuple(x), p.areaRng)) if a in setA]\n",
        "        i_list = [n for n, i in enumerate(p.imgIds)  if i in setI]\n",
        "        I0 = len(_pe.imgIds)\n",
        "        A0 = len(_pe.areaRng)\n",
        "        # retrieve E at each category, area range, and max number of detections\n",
        "        for k, k0 in enumerate(k_list):\n",
        "            Nk = k0*A0*I0\n",
        "            for a, a0 in enumerate(a_list):\n",
        "                Na = a0*I0\n",
        "                for m, maxDet in enumerate(m_list):\n",
        "                    E = [self.evalImgs[Nk + Na + i] for i in i_list]\n",
        "                    E = [e for e in E if not e is None]\n",
        "                    if len(E) == 0:\n",
        "                        continue\n",
        "                    dtScores = np.concatenate([e['dtScores'][0:maxDet] for e in E])\n",
        "\n",
        "                    # different sorting method generates slightly different results.\n",
        "                    # mergesort is used to be consistent as Matlab implementation.\n",
        "                    inds = np.argsort(-dtScores, kind='mergesort')\n",
        "                    dtScoresSorted = dtScores[inds]\n",
        "\n",
        "                    dtm  = np.concatenate([e['dtMatches'][:,0:maxDet] for e in E], axis=1)[:,inds]\n",
        "                    dtIg = np.concatenate([e['dtIgnore'][:,0:maxDet]  for e in E], axis=1)[:,inds]\n",
        "                    gtIg = np.concatenate([e['gtIgnore'] for e in E])\n",
        "                    npig = np.count_nonzero(gtIg==0 )\n",
        "                    if npig == 0:\n",
        "                        continue\n",
        "                    tps = np.logical_and(               dtm,  np.logical_not(dtIg) )\n",
        "                    fps = np.logical_and(np.logical_not(dtm), np.logical_not(dtIg) )\n",
        "\n",
        "                    tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)\n",
        "                    fp_sum = np.cumsum(fps, axis=1).astype(dtype=np.float)\n",
        "                    for t, (tp, fp) in enumerate(zip(tp_sum, fp_sum)):\n",
        "                        tp = np.array(tp)\n",
        "                        fp = np.array(fp)\n",
        "                        nd = len(tp)\n",
        "                        rc = tp / npig\n",
        "                        pr = tp / (fp+tp+np.spacing(1))\n",
        "                        q  = np.zeros((R,))\n",
        "                        ss = np.zeros((R,))\n",
        "\n",
        "                        if nd:\n",
        "                            recall[t,k,a,m] = rc[-1]\n",
        "                        else:\n",
        "                            recall[t,k,a,m] = 0\n",
        "\n",
        "                        # numpy is slow without cython optimization for accessing elements\n",
        "                        # use python array gets significant speed improvement\n",
        "                        pr = pr.tolist(); q = q.tolist()\n",
        "\n",
        "                        for i in range(nd-1, 0, -1):\n",
        "                            if pr[i] > pr[i-1]:\n",
        "                                pr[i-1] = pr[i]\n",
        "\n",
        "                        inds = np.searchsorted(rc, p.recThrs, side='left')\n",
        "                        try:\n",
        "                            for ri, pi in enumerate(inds):\n",
        "                                q[ri] = pr[pi]\n",
        "                                ss[ri] = dtScoresSorted[pi]\n",
        "                        except:\n",
        "                            pass\n",
        "                        precision[t,:,k,a,m] = np.array(q)\n",
        "                        scores[t,:,k,a,m] = np.array(ss)\n",
        "        self.eval = {\n",
        "            'params': p,\n",
        "            'counts': [T, R, K, A, M],\n",
        "            'date': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'precision': precision,\n",
        "            'recall':   recall,\n",
        "            'scores': scores,\n",
        "        }\n",
        "        toc = time.time()\n",
        "        print('DONE (t={:0.2f}s).'.format( toc-tic))\n",
        "\n",
        "    def summarize(self):\n",
        "        '''\n",
        "        Compute and display summary metrics for evaluation results.\n",
        "        Note this functin can *only* be applied on the default parameter setting\n",
        "        '''\n",
        "        def _summarize( ap=1, iouThr=None, areaRng='all', maxDets=100 ):\n",
        "            p = self.params\n",
        "            iStr = ' {:<18} {} @[ IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}'\n",
        "            titleStr = 'Average Precision' if ap == 1 else 'Average Recall'\n",
        "            typeStr = '(AP)' if ap==1 else '(AR)'\n",
        "            iouStr = '{:0.2f}:{:0.2f}'.format(p.iouThrs[0], p.iouThrs[-1]) \\\n",
        "                if iouThr is None else '{:0.2f}'.format(iouThr)\n",
        "\n",
        "            aind = [i for i, aRng in enumerate(p.areaRngLbl) if aRng == areaRng]\n",
        "            mind = [i for i, mDet in enumerate(p.maxDets) if mDet == maxDets]\n",
        "            if ap == 1:\n",
        "                # dimension of precision: [TxRxKxAxM]\n",
        "                s = self.eval['precision']\n",
        "                # IoU\n",
        "                if iouThr is not None:\n",
        "                    t = np.where(iouThr == p.iouThrs)[0]\n",
        "                    s = s[t]\n",
        "                s = s[:,:,:,aind,mind]\n",
        "            else:\n",
        "                # dimension of recall: [TxKxAxM]\n",
        "                s = self.eval['recall']\n",
        "                if iouThr is not None:\n",
        "                    t = np.where(iouThr == p.iouThrs)[0]\n",
        "                    s = s[t]\n",
        "                s = s[:,:,aind,mind]\n",
        "            if len(s[s>-1])==0:\n",
        "                mean_s = -1\n",
        "            else:\n",
        "                mean_s = np.mean(s[s>-1])\n",
        "            print(iStr.format(titleStr, typeStr, iouStr, areaRng, maxDets, mean_s))\n",
        "            return mean_s\n",
        "        def _summarizeDets():\n",
        "            stats = np.zeros((12,))\n",
        "            stats[0] = _summarize(1)\n",
        "            stats[1] = _summarize(1, iouThr=.5, maxDets=self.params.maxDets[2])\n",
        "            stats[2] = _summarize(1, iouThr=.75, maxDets=self.params.maxDets[2])\n",
        "            stats[3] = _summarize(1, areaRng='small', maxDets=self.params.maxDets[2])\n",
        "            stats[4] = _summarize(1, areaRng='medium', maxDets=self.params.maxDets[2])\n",
        "            stats[5] = _summarize(1, areaRng='large', maxDets=self.params.maxDets[2])\n",
        "            stats[6] = _summarize(0, maxDets=self.params.maxDets[0])\n",
        "            stats[7] = _summarize(0, maxDets=self.params.maxDets[1])\n",
        "            stats[8] = _summarize(0, maxDets=self.params.maxDets[2])\n",
        "            stats[9] = _summarize(0, areaRng='small', maxDets=self.params.maxDets[2])\n",
        "            stats[10] = _summarize(0, areaRng='medium', maxDets=self.params.maxDets[2])\n",
        "            stats[11] = _summarize(0, areaRng='large', maxDets=self.params.maxDets[2])\n",
        "            \n",
        "            #print(round(stats[0],3),' & ',round(stats[1],3),' & ',round(stats[2],3),' & ',round(stats[3],3),' & ',round(stats[4],3))\n",
        "            \n",
        "            data = { 'results' : [round(stats[0],3),round(stats[1],3),round(stats[2],3),round(stats[3],3),round(stats[4],3)] }\n",
        "            json_string = json.dumps(data)\n",
        "            with open(path_auto, 'w') as outfile:\n",
        "                outfile.write(json_string)\n",
        "            \n",
        "            \n",
        "            return stats\n",
        "        def _summarizeKps():\n",
        "            stats = np.zeros((10,))\n",
        "            stats[0] = _summarize(1, maxDets=20)\n",
        "            stats[1] = _summarize(1, maxDets=20, iouThr=.5)\n",
        "            stats[2] = _summarize(1, maxDets=20, iouThr=.75)\n",
        "            stats[3] = _summarize(1, maxDets=20, areaRng='medium')\n",
        "            stats[4] = _summarize(1, maxDets=20, areaRng='large')\n",
        "            stats[5] = _summarize(0, maxDets=20)\n",
        "            stats[6] = _summarize(0, maxDets=20, iouThr=.5)\n",
        "            stats[7] = _summarize(0, maxDets=20, iouThr=.75)\n",
        "            stats[8] = _summarize(0, maxDets=20, areaRng='medium')\n",
        "            stats[9] = _summarize(0, maxDets=20, areaRng='large')\n",
        "            return stats\n",
        "        if not self.eval:\n",
        "            raise Exception('Please run accumulate() first')\n",
        "        iouType = self.params.iouType\n",
        "        if iouType == 'segm' or iouType == 'bbox':\n",
        "            summarize = _summarizeDets\n",
        "        elif iouType == 'keypoints':\n",
        "            summarize = _summarizeKps\n",
        "        self.stats = summarize()\n",
        "\n",
        "    def __str__(self):\n",
        "        self.summarize()\n",
        "\n",
        "class Params:\n",
        "    '''\n",
        "    Params for coco evaluation api\n",
        "    '''\n",
        "    def setDetParams(self):\n",
        "        self.imgIds = []\n",
        "        self.catIds = []\n",
        "        # np.arange causes trouble.  the data point on arange is slightly larger than the true value\n",
        "        self.iouThrs = np.linspace(.5, 0.95, int(np.round((0.95 - .5) / .05)) + 1, endpoint=True)\n",
        "        self.recThrs = np.linspace(.0, 1.00, int(np.round((1.00 - .0) / .01)) + 1, endpoint=True)\n",
        "        self.maxDets = [1, 10, 100]\n",
        "        self.areaRng = [[0 ** 2, 1e5 ** 2], [0 ** 2, 32 ** 2], [32 ** 2, 96 ** 2], [96 ** 2, 1e5 ** 2]]\n",
        "        self.areaRngLbl = ['all', 'small', 'medium', 'large']\n",
        "        self.useCats = 1\n",
        "\n",
        "    def setKpParams(self):\n",
        "        self.imgIds = []\n",
        "        self.catIds = []\n",
        "        # np.arange causes trouble.  the data point on arange is slightly larger than the true value\n",
        "        self.iouThrs = np.linspace(.5, 0.95, int(np.round((0.95 - .5) / .05)) + 1, endpoint=True)\n",
        "        self.recThrs = np.linspace(.0, 1.00, int(np.round((1.00 - .0) / .01)) + 1, endpoint=True)\n",
        "        self.maxDets = [20]\n",
        "        self.areaRng = [[0 ** 2, 1e5 ** 2], [32 ** 2, 96 ** 2], [96 ** 2, 1e5 ** 2]]\n",
        "        self.areaRngLbl = ['all', 'medium', 'large']\n",
        "        self.useCats = 1\n",
        "        self.kpt_oks_sigmas = np.array([.26, .25, .25, .35, .35, .79, .79, .72, .72, .62,.62, 1.07, 1.07, .87, .87, .89, .89])/10.0\n",
        "\n",
        "    def __init__(self, iouType='segm'):\n",
        "        if iouType == 'segm' or iouType == 'bbox':\n",
        "            self.setDetParams()\n",
        "        elif iouType == 'keypoints':\n",
        "            self.setKpParams()\n",
        "        else:\n",
        "            raise Exception('iouType not supported')\n",
        "        self.iouType = iouType\n",
        "        # useSegm is deprecated\n",
        "        self.useSegm = None"
      ],
      "metadata": {
        "id": "RnJz3Sx8Mfbf"
      },
      "id": "RnJz3Sx8Mfbf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_final = {\n",
        "    'CENTERNET-HG104KPT1024' : [\n",
        "        {\n",
        "            'SEQ1' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "            'SEQ2' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "            'SEQ3' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "        \n",
        "            'SEQ4' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "            \n",
        "        }\n",
        "        \n",
        "        \n",
        "    ],\n",
        "    \n",
        "    'CENTERNET-RESNET101-V1' : [\n",
        "        {\n",
        "            'SEQ1' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "            'SEQ2' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "            'SEQ3' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "        \n",
        "            'SEQ4' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "            \n",
        "        }\n",
        "        \n",
        "        \n",
        "    ],\n",
        "    \n",
        "    'FASTER-INCEPTION-RESNET-V2-1024' : [\n",
        "        {\n",
        "            'SEQ1' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "            'SEQ2' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "            'SEQ3' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "        \n",
        "            'SEQ4' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "            \n",
        "        }\n",
        "        \n",
        "        \n",
        "    ],\n",
        "    \n",
        "    'ED3' : [\n",
        "        {\n",
        "            'SEQ1' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "            'SEQ2' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "            'SEQ3' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "        \n",
        "            'SEQ4' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "            \n",
        "        }\n",
        "        \n",
        "        \n",
        "    ],\n",
        "    \n",
        "    'ED4' : [\n",
        "        {\n",
        "            'SEQ1' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "            'SEQ2' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "            'SEQ3' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "        \n",
        "            'SEQ4' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "            \n",
        "        }\n",
        "        \n",
        "        \n",
        "    ],\n",
        "    \n",
        "    'ED5' : [\n",
        "        {\n",
        "            'SEQ1' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "            'SEQ2' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "            'SEQ3' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "        },\n",
        "        \n",
        "        {\n",
        "        \n",
        "            'SEQ4' : [\n",
        "                {'0'   : []},\n",
        "                {'10'  : []},\n",
        "                {'20'  : []},\n",
        "                {'30'  : []},\n",
        "                {'40'  : []},\n",
        "                {'50'  : []},\n",
        "                {'60'  : []},\n",
        "                {'70'  : []},\n",
        "                {'80'  : []},\n",
        "                {'90'  : []},\n",
        "                {'100' : []}\n",
        "            ]\n",
        "            \n",
        "        }\n",
        "        \n",
        "        \n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "AQb42ftAOhjv"
      },
      "id": "AQb42ftAOhjv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ebf0ce1",
      "metadata": {
        "id": "5ebf0ce1"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import json\n",
        "import time\n",
        "import statistics\n",
        "\n",
        "#PLEASE INSERT THE PATH TO GENERATE THE JSON WITH ALL THE OUTPUTS\n",
        "PATH_EVAL_JSON = ''\n",
        "SEQ_DATA_NAMEOK = ['SEQ1','SEQ2','SEQ3','SEQ4']\n",
        "SEQ_DATA_GTOK = ['/opt/share/CARPETA-DATOS/ANOTACIONESGITHUB/Sequence1/annotations/GT.json','/opt/share/CARPETA-DATOS/ANOTACIONESGITHUB/Sequence2/annotations/GT.json','/opt/share/CARPETA-DATOS/ANOTACIONESGITHUB/Sequence3/annotations/GT.json','/opt/share/CARPETA-DATOS/ANOTACIONESGITHUB/Sequence4/annotations/GT.json']\n",
        "MODELS_NAMES = ['CENTERNET-HG104KPT1024','CENTERNET-RESNET101-V1','FASTER-INCEPTION-RESNET-V2-1024','ED3','ED4','ED5']\n",
        "WSizeROK = [0, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1]\n",
        "classes = [3]\n",
        "score = 40\n",
        "#*****************************************************\n",
        "\n",
        "for model_name in MODELS_NAMES:\n",
        "    MODELS_NAMES = model_name\n",
        "    for num_sec in range(len(SEQ_DATA_NAMEOK)):\n",
        "        SELECTED_SEQ = num_sec\n",
        "        for num_r in range(len(WSizeROK)):\n",
        "            WSizeR = WSizeROK[num_r]\n",
        "            SEQ_DATA_GT = SEQ_DATA_GTOK[SELECTED_SEQ]\n",
        "            SEQ_DATA_NAME = SEQ_DATA_NAMEOK[SELECTED_SEQ]\n",
        "            PATH_MAP = PATH_EVAL+MODELS_NAMES+'/'+SEQ_DATA_NAME+'/'+str(WSizeR)+'/test_data_modificado.json'\n",
        "            PATH_DET = PATH_EVAL+MODELS_NAMES+'/'+SEQ_DATA_NAME+'/'+str(WSizeR)+'/test_data_modificado2.json'\n",
        "            \n",
        "            jsonString = SEQ_DATA_GT\n",
        "            dict_ids = {}\n",
        "            annFile = SEQ_DATA_GT\n",
        "            resFile = PATH_MAP\n",
        "\n",
        "            with open(jsonString) as json_file:\n",
        "                data = json.load(json_file)\n",
        "                for p3 in data['images']:\n",
        "                    data_s_image = p3['file_name'].replace('images/','')\n",
        "                    data_s_id = p3['id']\n",
        "                    dict_ids[data_s_image] = data_s_id   \n",
        "\n",
        "            annType = ['segm','bbox','keypoints']\n",
        "            annType = annType[1]      #specify type here\n",
        "            prefix = 'person_keypoints' if annType=='keypoints' else 'instances'\n",
        "            cocoGt=COCO(annFile)\n",
        "            cocoDt=cocoGt.loadRes(resFile)\n",
        "            dts = json.load(open(resFile,'r'))\n",
        "            imgIds = [imid['image_id'] for imid in dts]\n",
        "            imgIds = sorted(list(set(imgIds)))\n",
        "            cocoEval = COCOeval(cocoGt,cocoDt,annType)\n",
        "            cocoEval.params.imgIds  = imgIds\n",
        "            cocoEval.params.catIds = classes\n",
        "            cocoEval.evaluate()\n",
        "            cocoEval.accumulate()\n",
        "            cocoEval.summarize()\n",
        "\n",
        "            f1 = open(path_auto)\n",
        "            data1 = json.load(f1)\n",
        "            f1.close()\n",
        "\n",
        "            f = open(PATH_DET)\n",
        "            data = json.load(f)\n",
        "\n",
        "            counter = 0\n",
        "            media = 0\n",
        "            list_elements = []\n",
        "\n",
        "            for i in data:\n",
        "                counter = counter + 1\n",
        "                media = media + (int(i['number_subimages']))\n",
        "                numerador = int(i['number_subimages'])\n",
        "                list_elements.append(numerador)\n",
        "\n",
        "            f.close()\n",
        "\n",
        "            st_dev = statistics.pstdev(list_elements)\n",
        "            json_data = []\n",
        "            for salida in data1['results']:\n",
        "              json_data.append(salida)\n",
        "\n",
        "            json_data.append(round(media/counter,3))\n",
        "            json_data.append(round(st_dev,3))\n",
        "            \n",
        "            jsonString = SEQ_DATA_GT\n",
        "            dict_counter = {}\n",
        "\n",
        "            with open(jsonString) as json_file:\n",
        "                data = json.load(json_file)\n",
        "                for p3 in data['annotations']:\n",
        "                    identificador = p3['image_id']\n",
        "                    if p3['image_id'] in dict_counter:\n",
        "                        dict_counter[identificador] = dict_counter[identificador] + 1\n",
        "                    else:\n",
        "                        dict_counter[identificador] = 1\n",
        "            \n",
        "\n",
        "            json_my_annotations = PATH_MAP            \n",
        "            total_number_elements = 0\n",
        "            elements_per_frame = {}\n",
        "            score_per_frame = {}\n",
        "\n",
        "            with open(json_my_annotations) as json_result_file:\n",
        "                data_result = json.load(json_result_file)\n",
        "                for data in data_result:\n",
        "                    if data['score']*100 > score:\n",
        "                        total_number_elements = total_number_elements + 1\n",
        "                        id_imagen = data['image_id']\n",
        "                        if id_imagen not in elements_per_frame:\n",
        "                            elements_per_frame[id_imagen] = 1\n",
        "                        else:\n",
        "                            elements_per_frame[id_imagen] = elements_per_frame[id_imagen]+1\n",
        "                        if id_imagen not in score_per_frame:\n",
        "                            score_per_frame[id_imagen]= [data['score']*100]\n",
        "                        else:\n",
        "                            lista = score_per_frame[id_imagen]\n",
        "                            lista.append(data['score']*100)\n",
        "                            score_per_frame[id_imagen] = lista\n",
        "\n",
        "            list_elements = []\n",
        "            for element in elements_per_frame.keys():\n",
        "                list_elements.append(elements_per_frame[element])\n",
        "          \n",
        "            st_dev = statistics.pstdev(list_elements)\n",
        "            json_data.append(round(sum(list_elements) / len(list_elements),3))\n",
        "            json_data.append(round(st_dev,3))\n",
        "            \n",
        "            list_score = []\n",
        "            score_finals = {}\n",
        "\n",
        "            for key, score in score_per_frame.items():\n",
        "                suma = 0\n",
        "                for puntuacion in score:\n",
        "                    suma = suma + puntuacion\n",
        "                suma = suma / dict_counter[key]\n",
        "                list_score.append(suma)\n",
        "           \n",
        "            st_dev2 = statistics.pstdev(list_score)\n",
        "            json_data.append(round(sum(list_score) / len(list_score),3))\n",
        "            json_data.append(round(st_dev2,3))\n",
        "            data_final[MODELS_NAMES][SELECTED_SEQ][SEQ_DATA_NAME][int(WSizeR*10)] = json_data\n",
        "        \n",
        "json_pareto = json.dumps(data_final)   \n",
        "PATH_EVAL_JSON = PATH_EVAL_JSON + 'OUTPUT.json'    \n",
        "with open(PATH_EVAL_JSON, 'w') as outfile:\n",
        "    outfile.write(json_pareto)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "GITHUB-PY.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}